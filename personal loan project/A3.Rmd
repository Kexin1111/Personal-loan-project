#Q1
```{r}
library(tidyverse)
library(tidyr)
df <- read.csv("C:/Users/1/Desktop/spotify_top_charts_22.csv")
```
a.The song "Pepas" by singer Farruko.
b.I love the rhythm of the song and the fun and carefree outlook on life revealed in its lyrics.
```{r}
sing <- df %>% filter(track_name=="Pepas")

pepas <- sing %>% 
  select(track_name, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, tempo, duration_ms) %>% 
  gather(Variable, Value)
view(pepas)
```
#Q2
```{r}
view(sing)
```
#Q3
```{r}
df2 <- read.csv("C:/Users/1/Desktop/spotify.csv")
str(df2)
```
a.The type of 'target' is integer, not a factor.
```{r}
df2$target <- factor(df2$target)
str(df2$target)
```
```{r}
levels(df2$target)
table(df2$target)
```
b.The unique values that target variable has are "0" and "1", "0" have 997 records and "1" has 1020 records.
#Q4
```{r}
anyNA(df2)
```
#Q5
```{r}
colnames(df2)

df2 <- df2 %>% select(acousticness, danceability, duration_ms, energy, instrumentalness, liveness, loudness, speechiness, tempo, target, song_title, artist)
```
#Q6
```{r}
set.seed(7575556)
df2 <- slice_sample(df2, prop=1)
train <- slice_head(df2, prop=0.6)
valid <- slice_tail(df2, prop=0.4)
```
#Q7
```{r}
train2 <- split(train, train$target)

means_0 <- sapply(train2[[1]][, c("danceability", "energy", "loudness", "speechiness", "acousticness", "instrumentalness", "liveness", "tempo", "duration_ms")], mean)
means_1 <- sapply(train2[[2]][, c("danceability", "energy", "loudness", "speechiness", "acousticness", "instrumentalness", "liveness", "tempo", "duration_ms")], mean)

perc_dif <- ((means_1 - means_0) / means_0) * 100

perc_dif
```
b. The variables that show a percentage difference of 10% or more are as follows:loudness, speechiness, acousticness, instrumentalness, duration_ms.
```{r}
colnames(train)
train3 <- train %>% select(acousticness, duration_ms, instrumentalness, loudness, speechiness, target, song_title, artist)
```
c. Removing this kind of variables from a k-nn model can help to improve the model's performance by reducing the redundancy in the data, which can lead to overfitting. By focusing on the most informative variables, the model can more accurately capture the patterns in the data.
#Q8
```{r}
#library(caret)
t_norm <- scale(train3[,1:5])
t_norm <- data.frame(t_norm)
t_norm$target <- train3$target
t_norm$song_title <- train3$song_title
t_norm$artist <- train3$artist
```
```{r}
sing2 <- sing %>% select(acousticness, duration_ms, instrumentalness, loudness, speechiness)
```

#Q9
```{r}
library(FNN)

test_sing <- knn(train=t_norm[,1:5], test=sing2[,1:5], cl=t_norm[,6], k=7)

test_sing
```
For the song 'Pepas', George will like it. The model predicted outcome is 1.
```{r}
attr(test_sing, "nn.index")
```
```{r}
index_n <- attr(test_sing, "nn.index")[1, ]
data_n <- t_norm[index_n, ] 
data_n <- data_n %>% select(song_title, artist, target)
data_n
```
#Q10
```{r}
valid3 <- valid %>% select(acousticness, duration_ms, instrumentalness, loudness, speechiness, target, song_title, artist)
v_norm <- scale(valid3[,1:5])
v_norm <- data.frame(v_norm)
v_norm$target <- valid3$target
```
```{r}
acc <- c()
for(k in seq(1, 30, 1)){
  m <- knn(train=t_norm[,1:5], test=v_norm[,1:5], cl=t_norm[,6], k=k)
  acc <- c(acc, mean(v_norm[,6]==m))
}
```
#Q11
```{r}
ggplot() + geom_point(aes(x=seq(1, 30, 1), y=acc)) +
  geom_line(aes(x=seq(1, 30, 1), y=acc))
```
The optimal k-value determined is 27.
#Q12
```{r}
m27 <- knn(train=t_norm[,1:5], test=sing2[,1:5], cl=t_norm[,6], k=27)
m27
```
I got the final prediction target of 1, which means George will like this song, no change. This time I  got 27 k-nearest neighbors.
```{r}
index <- attr(m27, "nn.index")[1, ]
m27_n <- t_norm[index, ] %>% select(song_title, artist, target)
m27_n
```









